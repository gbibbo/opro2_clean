#!/bin/bash
#SBATCH --job-name=opro_varied_lora
#SBATCH --partition=3090
#SBATCH --gpus=1
#SBATCH --cpus-per-task=12
#SBATCH --mem=48G
#SBATCH --time=05:00:00
#SBATCH --exclude=aisurrey14,aisurrey19
#SBATCH --output=/mnt/fast/nobackup/users/gb0048/opro2_clean/logs/opro_varied_lora_%j.out
#SBATCH --error=/mnt/fast/nobackup/users/gb0048/opro2_clean/logs/opro_varied_lora_%j.err

# =============================================================================
# OPRO with Varied Seed Prompts on LoRA Model
# =============================================================================
# Executes OPRO with 15 diverse seed prompts (descriptive, binary, with
# definitions, with examples, multiple choice, etc.) on the LoRA fine-tuned model
# =============================================================================

set -euo pipefail
set -x

REPO_CLEAN="/mnt/fast/nobackup/users/gb0048/opro2_clean"
REPO_DATA="/mnt/fast/nobackup/users/gb0048/opro2"
CONTAINER="$REPO_DATA/qwen_pipeline_v2.sif"
SEED=42

echo "[INFO] ========================================================================"
echo "[INFO] OPRO with Varied Seeds - LoRA Model - INICIO: $(date)"
echo "[INFO] ========================================================================"
echo "[INFO] Seed: $SEED"
echo "[INFO] Samples per iteration: 30"
echo "[INFO] Decoding mode: open (allows free-form answers)"
echo "[INFO] Seed prompts: 15 varied templates"
echo "[INFO] GPU Info:"
nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv
echo "[INFO] Node: $(hostname)"
echo "[INFO] ========================================================================"

cd "$REPO_CLEAN"

# Configurar cache de HuggingFace
export HF_HOME="/mnt/fast/nobackup/users/gb0048/.cache/huggingface"
export TRANSFORMERS_CACHE="$HF_HOME/transformers"
export HF_HUB_CACHE="$HF_HOME/hub"
mkdir -p "$HF_HOME" "$TRANSFORMERS_CACHE" "$HF_HUB_CACHE"

export PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True"

# Rutas
DATA_ROOT="$REPO_DATA/data"
CHECKPOINT="checkpoints/qwen_lora_seed${SEED}/final"
OUTPUT_DIR="results/opro_varied_seed${SEED}/lora"
DEV_CSV="$DATA_ROOT/processed/experimental_variants/dev_metadata.csv"
SEEDS_FILE="$REPO_CLEAN/prompts/open_descriptive_seeds.json"

# Verificar prerequisites
if [ ! -f "$CONTAINER" ]; then
    echo "[ERROR] Container not found: $CONTAINER"
    exit 1
fi

if [ ! -d "$CHECKPOINT" ]; then
    echo "[ERROR] Checkpoint not found: $CHECKPOINT"
    exit 1
fi

if [ ! -f "$SEEDS_FILE" ]; then
    echo "[ERROR] Seeds file not found: $SEEDS_FILE"
    exit 1
fi

# Limpiar output anterior
echo "[INFO] Preparando directorio de salida..."
rm -rf "$OUTPUT_DIR"
mkdir -p "$OUTPUT_DIR"

# Test CUDA
echo "[INFO] ========================================================================"
echo "[INFO] Testing CUDA availability inside container..."
echo "[INFO] ========================================================================"

apptainer exec --nv \
    --pwd "$REPO_CLEAN" \
    --env HF_HOME="$HF_HOME" \
    "$CONTAINER" python3 -c "
import torch
print(f'CUDA available: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'CUDA device: {torch.cuda.get_device_name(0)}')
    x = torch.randn(10, 10).cuda()
    print(f'Test tensor on GPU: {x.device}')
    print('CUDA test: ✓ PASSED')
else:
    print('ERROR: CUDA not available!')
    exit(1)
"

CUDA_TEST_EXIT=$?
if [ $CUDA_TEST_EXIT -ne 0 ]; then
    echo "[ERROR] ✗ CUDA test failed. Aborting job."
    exit 1
fi

echo "[INFO] ✓ CUDA test passed. Proceeding with OPRO..."

# Ejecutar OPRO con prompts variados
echo "[INFO] ========================================================================"
echo "[INFO] Ejecutando OPRO con 15 prompts semilla variados"
echo "[INFO] ========================================================================"
echo "[INFO]"
echo "[INFO] Características:"
echo "[INFO]   - Modelo: LoRA (fine-tuned)"
echo "[INFO]   - Checkpoint: $CHECKPOINT"
echo "[INFO]   - Iteraciones: 15"
echo "[INFO]   - Muestras por iteración: 30"
echo "[INFO]   - Candidatos por iteración: 8"
echo "[INFO]   - Decoding mode: open (permite respuestas libres)"
echo "[INFO]   - Templates semilla: 15 prompts con máxima variedad"
echo "[INFO]"
echo "[INFO] Tipos de prompts incluidos:"
echo "[INFO]   - Descriptivos abiertos (e.g., 'What do you hear?')"
echo "[INFO]   - Binarios directos (e.g., 'SPEECH or NONSPEECH?')"
echo "[INFO]   - Con definiciones (e.g., 'SPEECH means human voice...')"
echo "[INFO]   - Con ejemplos (e.g., 'Example: beeping → NONSPEECH')"
echo "[INFO]   - Multiple choice (e.g., 'A) Speech or B) Other?')"
echo "[INFO]   - YES/NO format"
echo "[INFO]   - Técnicos y ultra-cortos"
echo "[INFO] ========================================================================"

apptainer exec --nv \
    --pwd "$REPO_CLEAN" \
    --env HF_HOME="$HF_HOME" \
    --env TRANSFORMERS_CACHE="$TRANSFORMERS_CACHE" \
    --env HF_HUB_CACHE="$HF_HUB_CACHE" \
    --env PYTORCH_CUDA_ALLOC_CONF="$PYTORCH_CUDA_ALLOC_CONF" \
    "$CONTAINER" python3 scripts/opro_post_ft_v2.py \
        --checkpoint "$CHECKPOINT" \
        --train_csv "$DEV_CSV" \
        --output_dir "$OUTPUT_DIR" \
        --num_iterations 15 \
        --samples_per_iter 30 \
        --num_candidates 8 \
        --seed "$SEED" \
        --decoding open \
        --templates_file "$SEEDS_FILE"

EXIT_CODE=$?

echo "[INFO] ========================================================================"
if [ $EXIT_CODE -eq 0 ]; then
    echo "[INFO] ✓ OPRO VARIED (LoRA) COMPLETED SUCCESSFULLY"
    echo "[INFO] Output: $OUTPUT_DIR"
    echo "[INFO] Best prompt: $OUTPUT_DIR/best_prompt.txt"
    if [ -f "$OUTPUT_DIR/best_prompt.txt" ]; then
        echo "[INFO] Best prompt content:"
        cat "$OUTPUT_DIR/best_prompt.txt"
    fi
else
    echo "[ERROR] ✗ OPRO VARIED (LoRA) FAILED (Exit code: $EXIT_CODE)"
fi
echo "[INFO] FIN: $(date)"
echo "[INFO] ========================================================================"

exit $EXIT_CODE
