#!/bin/bash
#SBATCH --job-name=test_cuda
#SBATCH --partition=3090
#SBATCH --gpus=1
#SBATCH --cpus-per-task=2
#SBATCH --mem=16G
#SBATCH --time=00:05:00
#SBATCH --output=/mnt/fast/nobackup/users/gb0048/opro2_clean/logs/test_cuda_%j.out
#SBATCH --error=/mnt/fast/nobackup/users/gb0048/opro2_clean/logs/test_cuda_%j.err

set -euo pipefail
set -x

REPO_CLEAN="/mnt/fast/nobackup/users/gb0048/opro2_clean"
REPO_DATA="/mnt/fast/nobackup/users/gb0048/opro2"
CONTAINER="$REPO_DATA/qwen_pipeline_v2.sif"

echo "[INFO] Testing CUDA availability"
nvidia-smi

cd "$REPO_CLEAN"

export HF_HOME="/mnt/fast/nobackup/users/gb0048/.cache/huggingface"
export TRANSFORMERS_CACHE="$HF_HOME/transformers"
export HF_HUB_CACHE="$HF_HOME/hub"

# Test CUDA inside container
apptainer exec --nv \
    --pwd "$REPO_CLEAN" \
    --env HF_HOME="$HF_HOME" \
    "$CONTAINER" python3 -c "
import torch
print(f'PyTorch version: {torch.__version__}')
print(f'CUDA available: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'CUDA device count: {torch.cuda.device_count()}')
    print(f'CUDA device name: {torch.cuda.get_device_name(0)}')
    print(f'CUDA version: {torch.version.cuda}')
    # Try to create a tensor on GPU
    x = torch.zeros(10, 10).cuda()
    print('Successfully created tensor on GPU')
else:
    print('ERROR: CUDA not available!')
"

echo "[INFO] CUDA test completed"
